{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in progress. I will update when I incorporate more features.\n",
    "# I've based my processing on scripts by SRK. Thanks!\n",
    "\n",
    "\n",
    "\"\"\" __author__ : Wrosinski \"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, fbeta_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "numerical_cols = ['age', 'antiguedad', 'renta']\n",
    "\n",
    "feature_cols = ['ind_actividad_cliente', \n",
    "                \"ind_empleado\", \"pais_residencia\" ,\"sexo\" , \"ind_nuevo\", \n",
    "                 \"nomprov\", \"segmento\", 'indrel', 'tiprel_1mes', 'indresi', 'indext',\n",
    "               'conyuemp', 'indfall', 'canal_entrada']\n",
    "\n",
    "dtype_list = {'ind_cco_fin_ult1': 'float16', 'ind_deme_fin_ult1': 'float16', 'ind_aval_fin_ult1': 'float16', 'ind_valo_fin_ult1': 'float16', 'ind_reca_fin_ult1': 'float16', 'ind_ctju_fin_ult1': 'float16', 'ind_cder_fin_ult1': 'float16', 'ind_plan_fin_ult1': 'float16', 'ind_fond_fin_ult1': 'float16', 'ind_hip_fin_ult1': 'float16', 'ind_pres_fin_ult1': 'float16', 'ind_nomina_ult1': 'float16', 'ind_cno_fin_ult1': 'float16', 'ncodpers': 'int64', 'ind_ctpp_fin_ult1': 'float16', 'ind_ahor_fin_ult1': 'float16', 'ind_dela_fin_ult1': 'float16', 'ind_ecue_fin_ult1': 'float16', 'ind_nom_pens_ult1': 'float16', 'ind_recibo_ult1': 'float16', 'ind_deco_fin_ult1': 'float16', 'ind_tjcr_fin_ult1': 'float16', 'ind_ctop_fin_ult1': 'float16', 'ind_viv_fin_ult1': 'float16', 'ind_ctma_fin_ult1': 'float16'}\n",
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_actividad_cliente\n",
      "(1000000, 1) (929615, 1)\n",
      "ind_empleado\n",
      "(1000000, 2) (929615, 2)\n",
      "pais_residencia\n",
      "(1000000, 3) (929615, 3)\n",
      "sexo\n",
      "(1000000, 4) (929615, 4)\n",
      "ind_nuevo\n",
      "(1000000, 5) (929615, 5)\n",
      "nomprov\n",
      "(1000000, 6) (929615, 6)\n",
      "segmento\n",
      "(1000000, 7) (929615, 7)\n",
      "indrel\n",
      "(1000000, 8) (929615, 8)\n",
      "tiprel_1mes\n",
      "(1000000, 9) (929615, 9)\n",
      "indresi\n",
      "(1000000, 10) (929615, 10)\n",
      "indext\n",
      "(1000000, 11) (929615, 11)\n",
      "conyuemp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liouscott/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 12) (929615, 12)\n",
      "indfall\n",
      "(1000000, 13) (929615, 13)\n",
      "canal_entrada\n",
      "(1000000, 14) (929615, 14)\n",
      "Categorical features loaded.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./input/\"\n",
    "train_file = data_path + \"train_ver2.csv\"\n",
    "test_file = data_path + \"test_ver2.csv\"\n",
    "train_size = 13647309\n",
    "nrows = 1000000 # change this value to read more rows from train\n",
    "start_index = train_size - nrows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ind, col in enumerate(feature_cols):\n",
    "    print(col)\n",
    "    train = pd.read_csv(train_file, usecols=[col])\n",
    "    test = pd.read_csv(test_file, usecols=[col])\n",
    "    train.fillna(-99, inplace=True)\n",
    "    test.fillna(-99, inplace=True)\n",
    "    if train[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].values) + list(test[col].values))\n",
    "        temp_train_X = le.transform(list(train[col].values)).reshape(-1,1)[start_index:,:]\n",
    "        temp_test_X = le.transform(list(test[col].values)).reshape(-1,1)\n",
    "    else:\n",
    "        temp_train_X = np.array(train[col]).reshape(-1,1)[start_index:,:]\n",
    "        temp_test_X = np.array(test[col]).reshape(-1,1)\n",
    "    if ind == 0:\n",
    "        train_X = temp_train_X.copy()\n",
    "        test_X = temp_test_X.copy()\n",
    "    else:\n",
    "        train_X = np.hstack([train_X, temp_train_X])\n",
    "        test_X = np.hstack([test_X, temp_test_X])\n",
    "    print(train_X.shape, test_X.shape)\n",
    "del train\n",
    "del test\n",
    "print (\"Categorical features loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liouscott/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antiguedad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liouscott/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renta\n",
      "Numeric features loaded.\n"
     ]
    }
   ],
   "source": [
    "for ind, col in enumerate(numerical_cols):\n",
    "    print(col)\n",
    "    train = pd.read_csv(train_file, usecols=[col])\n",
    "    test = pd.read_csv(test_file, usecols=[col])\n",
    "    train.fillna(-1, inplace=True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "    if train[col].dtype == \"object\":\n",
    "\n",
    "        temp_train_X = pd.to_numeric(train[col], 'coerce').fillna(-1).astype('float64').values.reshape(-1,1)[start_index:,:]\n",
    "        temp_test_X = pd.to_numeric(test[col], 'coerce').fillna(-1).astype('float64').values.reshape(-1,1)\n",
    "    else:\n",
    "        temp_train_X = np.array(pd.to_numeric(train[col], 'coerce').fillna(0).astype('float64')).reshape(-1,1)[start_index:,:]\n",
    "        temp_test_X = np.array(pd.to_numeric(test[col], 'coerce').fillna(0).astype('float64')).reshape(-1,1)\n",
    "    if ind == 0:\n",
    "        train_X_f = temp_train_X.copy()\n",
    "        test_X_f = temp_test_X.copy()\n",
    "    else:\n",
    "        train_X_f = np.hstack([train_X_f, temp_train_X])\n",
    "        test_X_f = np.hstack([test_X_f, temp_test_X])\n",
    "        \n",
    "print (\"Numeric features loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liouscott/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 24)\n",
      "136000112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liouscott/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " F1 score:  0.0288375422219856 ROC AUC score:  0.5017018679038129\n",
      "Test set predictions done.\n",
      "Getting last instance dict..\n",
      "Creating submission..\n"
     ]
    }
   ],
   "source": [
    "#Dense encoding:\n",
    "full_train = np.hstack([train_X, train_X_f])\n",
    "\n",
    "full_test = np.hstack([test_X, test_X_f])\n",
    "\n",
    "#Sparse encoding (OneHot):\n",
    "scaler = RobustScaler()\n",
    "temp = csr_matrix(scaler.fit_transform(train_X_f))\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "OH = enc.fit_transform(train_X)\n",
    "OH_csr = csr_matrix(OH)\n",
    "\n",
    "sparse_train = hstack([temp, OH_csr], format = \"csr\")\n",
    "\n",
    "\n",
    "#Read target data:\n",
    "train_y = pd.read_csv(train_file, usecols=['ncodpers']+target_cols, dtype=dtype_list)\n",
    "last_instance_df = train_y.drop_duplicates('ncodpers', keep='last')\n",
    "train_y = np.array(train_y.fillna(0)).astype('int')[start_index:,1:]\n",
    "print(train_y.shape)\n",
    "\n",
    "\n",
    "#Train/validation split, optional.\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(full_train, train_y, test_size = 0.2, random_state = 669)\n",
    "nb_classes = train_y.shape[1]\n",
    "print (sys.getsizeof(full_train))\n",
    "\n",
    "\n",
    "#Model\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 100,\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "\n",
    "preds = []\n",
    "preds_test = []\n",
    "\n",
    "folds = 5\n",
    "kf = KFold(n_splits = folds)\n",
    "\n",
    "for ind, col in enumerate(train_y.T):\n",
    "    \n",
    "    fold_preds = []\n",
    "    fold_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(full_train):\n",
    "        \n",
    "        X_train, X_val = full_train[train_index], full_train[test_index]\n",
    "        y_train, y_val = col[train_index], col[test_index]\n",
    "\n",
    "        d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "        d_valid = xgb.DMatrix(X_val, label=y_val)\n",
    "        d_test = xgb.DMatrix(full_test)\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n",
    "\n",
    "        clf = xgb.train(xgb_params,\n",
    "                    d_train,\n",
    "                    300,\n",
    "                    watchlist,\n",
    "                    early_stopping_rounds = 50, verbose_eval = True)\n",
    "\n",
    "        probs = clf.predict(d_valid)\n",
    "        probs_test = clf.predict(d_test)\n",
    "        \n",
    "        fold_preds.append(probs)\n",
    "        fold_test.append(probs_test)\n",
    "        \n",
    "    preds.append(fold_preds)\n",
    "    preds_test.append(fold_test)\n",
    "\n",
    "preds_a = np.asarray(preds)\n",
    "preds_at = np.asarray(preds_test)\n",
    "\n",
    "means = []\n",
    "for i in preds_a:\n",
    "    j = np.mean(i, axis = 0)\n",
    "    means.append(j)\n",
    "    \n",
    "means_t = []\n",
    "for i in preds_at:\n",
    "    j = np.mean(i, axis = 0)\n",
    "    means_t.append(j)\n",
    "\n",
    "    \n",
    "means_b = np.asarray(means).T\n",
    "means_tb = np.asarray(means_t).T\n",
    "\n",
    "ROC = roc_auc_score(y_val2, means_b)\n",
    "\n",
    "means_b[means_b >= 0.5] = 1\n",
    "means_b[means_b < 0.5] = 0\n",
    "F1 = f1_score(y_val2, means_b, average = \"macro\")\n",
    "\n",
    "print ('\\n', \"F1 score: \", F1, \"ROC AUC score: \", ROC)\n",
    "\n",
    "\n",
    "#Making proper predictions for test data.\n",
    "preds = means_tb\n",
    "print (\"Test set predictions done.\")\n",
    "\n",
    "\n",
    "print(\"Getting last instance dict..\")\n",
    "last_instance_df = last_instance_df.fillna(0).astype('int')\n",
    "cust_dict = {}\n",
    "target_cols = np.array(target_cols)\n",
    "for ind, row in last_instance_df.iterrows():\n",
    "    cust = row['ncodpers']\n",
    "    used_products = set(target_cols[np.array(row[1:])==1])\n",
    "    cust_dict[cust] = used_products\n",
    "\n",
    "\n",
    "print(\"Creating submission..\")\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)\n",
    "test_id = np.array(pd.read_csv(test_file, usecols=['ncodpers'])['ncodpers'])\n",
    "final_preds = []\n",
    "for ind, pred in enumerate(preds):\n",
    "    cust = test_id[ind]\n",
    "    top_products = target_cols[pred]\n",
    "    used_products = cust_dict.get(cust,[])\n",
    "    new_top_products = []\n",
    "    for product in top_products:\n",
    "        if product not in used_products:\n",
    "            new_top_products.append(product)\n",
    "        if len(new_top_products) == 7:\n",
    "            break\n",
    "    final_preds.append(\" \".join(new_top_products))\n",
    "\n",
    "len(final_preds[0])\n",
    "len(final_preds)\n",
    "final_preds[0]\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "out_df.to_csv('XGBoost_try_13.11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.asarray(means_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
