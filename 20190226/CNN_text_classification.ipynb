{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download stopwords corpus from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading preprocessed pre-trained google news vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assigning index to each categories and reverse the keys and item values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "EMBEDDING_FILE = \"GoogleNews-vectors-negative300.bin\"\n",
    "category_index = {\"clothing\":0, \"camera\":1, \"home-appliances\":2}\n",
    "category_reverse_index = dict((y,x) for (x,y) in category_index.items())\n",
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clothing': 0, 'camera': 1, 'home-appliances': 2}\n",
      "{0: 'clothing', 1: 'camera', 2: 'home-appliances'}\n",
      "{'what', 'themselves', 'now', 'having', 'couldn', 'wasn', \"she's\", 'through', 'we', 'because', 'it', 'a', 'of', 'nor', 'same', 'ma', 'into', 'on', 'd', 'hadn', 'the', \"that'll\", 'y', \"hadn't\", 'm', 'did', 'don', 'hers', \"weren't\", 'between', \"mustn't\", 'any', \"mightn't\", 'wouldn', 'that', 'do', 'those', 'over', 'aren', 'their', 'you', 'whom', 'both', 'in', 'shan', 'our', 'ain', 'herself', 'there', 'i', 'who', 'will', 'she', \"it's\", 'have', 'which', \"you're\", 'they', 'ours', 't', \"shouldn't\", 'were', 'theirs', 'an', 'being', 'about', \"you'll\", 'some', \"needn't\", \"couldn't\", 'won', 's', 'few', 'such', 'yours', 'itself', 'mightn', 'her', 'been', 'above', 'does', 'below', 'has', \"don't\", 'himself', 'when', 'myself', 'its', 'more', 'as', \"haven't\", 'shouldn', 'me', 'was', 'my', 'then', 'll', 'and', 'after', 'to', 'too', 'up', 'but', 'he', 'had', 'haven', \"won't\", 'am', 'weren', 'why', 'is', 'all', 'so', 'didn', 'just', 'should', \"you've\", 'most', 'how', 'if', 'isn', 'once', \"doesn't\", 'where', 'or', 'needn', \"wouldn't\", 'own', \"isn't\", 'while', 'out', 're', 'further', 'off', 'by', 've', 'again', 'are', 'before', 'o', 'each', 'other', 'until', 'be', \"aren't\", 'from', 'very', 'doesn', 'no', 'hasn', 'these', 'with', 'under', \"didn't\", 'him', 'for', 'against', 'only', 'yourselves', 'this', \"should've\", 'your', 'them', 'during', 'than', 'can', 'yourself', 'mustn', 'doing', \"shan't\", 'not', \"you'd\", \"hasn't\", 'ourselves', \"wasn't\", 'at', 'here', 'his', 'down'}\n"
     ]
    }
   ],
   "source": [
    "print(category_index)\n",
    "print(category_reverse_index)\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading clothing, cameras, home_appliance csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure there are no null values in the datasets\n",
      "Has null values:  False\n",
      "Has null values:  False\n",
      "Has null values:  False\n"
     ]
    }
   ],
   "source": [
    "clothing = pd.read_csv(\"product-titles-cnn-data/clothing.tsv\", sep='\\t')\n",
    "cameras = pd.read_csv(\"product-titles-cnn-data/cameras.tsv\", sep='\\t')\n",
    "home_appliances = pd.read_csv(\"product-titles-cnn-data/home.tsv\", sep='\\t')\n",
    "\n",
    "datasets = [clothing, cameras, home_appliances]\n",
    "\n",
    "print(\"Make sure there are no null values in the datasets\")\n",
    "for data in datasets:\n",
    "    print(\"Has null values: \", data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1410 Casual Short Sleeve Graphic Print Women's Maroon, Grey Top\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing.iloc[100].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autosity detective survilliance black hd camera button spy product camcorder(black)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cameras.iloc[100].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connect z bt-m51n corded landline phone(black & white)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_appliances.iloc[100].title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords and apply on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text= text.strip().lower().split()\n",
    "    text = filter(lambda word: word not in STOPWORDS, text)\n",
    "    return \" \".join(text)\n",
    "    \n",
    "for dataset in datasets:\n",
    "    dataset['title'] = dataset['title'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = clothing['title'] + cameras['title'] + home_appliances['title']\n",
    "all_texts = all_texts.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1410 casual short sleeve graphic print women's maroon, grey topautosity detective survilliance black hd camera button spy product camcorder(black)connect z bt-m51n corded landline phone(black & white)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize all datasets into pre-set max_nb_words (20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1410 casual short sleeve graphic print women's maroon, grey topautosity detective survilliance black hd camera button spy product camcorder(black)connect z bt-m51n corded landline phone(black & white)\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert texts into sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_sequences = tokenizer.texts_to_sequences(clothing['title'])\n",
    "electronics_sequences = tokenizer.texts_to_sequences(cameras['title'])\n",
    "home_appliances_sequences = tokenizer.texts_to_sequences(home_appliances['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410 casual short sleeve graphic print women's maroon, grey top\n",
      "10\n",
      "[72, 10, 135, 31, 268, 64, 3, 149, 67, 494]\n"
     ]
    }
   ],
   "source": [
    "print(clothing.iloc[100].title)\n",
    "print(len(clothing_sequences[100]))\n",
    "print(clothing_sequences[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make each row the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_data = pad_sequences(clothing_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "electronics_data = pad_sequences(electronics_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "home_appliances_data = pad_sequences(home_appliances_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410 casual short sleeve graphic print women's maroon, grey top\n",
      "30\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  72  10 135  31 268  64   3 149  67 494]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1410 women's a-line pink, white dress\n",
      "30\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0   72    3   84   93   30\n",
      "    4 2671]\n"
     ]
    }
   ],
   "source": [
    "print(clothing.iloc[100].title)\n",
    "print(len(clothing_data[100]))\n",
    "print(clothing_data[100])\n",
    "print('-'*100)\n",
    "print(clothing.iloc[150].title)\n",
    "print(len(clothing_data[150]))\n",
    "print(clothing_data[150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vetically stack up all data from three datasets of three categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing: \t\t [1. 0. 0.]\n",
      "camera: \t\t [0. 1. 0.]\n",
      "home appliances: \t [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "## The category (y-axis or label) is converted to convnet’s understandable format by using the \n",
    "## keras.util method to_categorical.\n",
    "print(\"clothing: \\t\\t\", to_categorical(category_index[\"clothing\"], 3))\n",
    "print(\"camera: \\t\\t\", to_categorical(category_index[\"camera\"], 3))\n",
    "print(\"home appliances: \\t\", to_categorical(category_index[\"home-appliances\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined data shape:  (405493, 30)\n",
      "combined category/label shape:  (405493, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.vstack((clothing_data, electronics_data, home_appliances_data)) #vertically conbine all data\n",
    "category = pd.concat([clothing['category'], cameras['category'], home_appliances['category']]).values\n",
    "category = to_categorical(category)\n",
    "print(\"combined data shape: \", data.shape)\n",
    "print(\"combined category/label shape: \", category.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.3\n",
    "indices = np.arange(data.shape[0]) # get sequence of row index\n",
    "np.random.shuffle(indices) # shuffle the row indexes\n",
    "data = data[indices] # shuffle data/product-titles/x-axis\n",
    "category = category[indices] # shuffle labels/category/y-axis\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = category[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = category[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pretrained vectors from google news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors of word2vec\n"
     ]
    }
   ],
   "source": [
    "## Word2Vec brings in semantic similarity info which can be leveraged by the convnets. \n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd word out: carrot\n",
      "----------\n",
      "Cosine similarity between TV and HBO: 0.6130649\n",
      "----------\n",
      "Cosine similarity between TV and carrot: 0.055450663\n",
      "----------\n",
      "Most similar words to Computers: computer, laptops, PCs, laptop_computers, desktop_computers, Computers, laptop, notebook_computers, Dell_OptiPlex_desktop, automated_seismographs\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"Odd word out:\", word2vec.doesnt_match(\"banana apple grapes carrot\".split()))\n",
    "print(\"-\"*10)\n",
    "print(\"Cosine similarity between TV and HBO:\", word2vec.similarity(\"tv\", \"hbo\"))\n",
    "print(\"-\"*10)\n",
    "print(\"Cosine similarity between TV and carrot:\", word2vec.similarity(\"tv\", \"carrot\"))\n",
    "print(\"-\"*10)\n",
    "print(\"Most similar words to Computers:\", \", \".join(map(lambda x: x[0], word2vec.most_similar(\"computers\"))))\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking number of words in data not found in pre-trained google news\n",
    "The null word embeddings indicate the number of words not found in our pre-trained vectors (In this case Google News). This could possibly be unique words for brands in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 1473\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0], # or len(word_index) + 1\n",
    "                            embedding_matrix.shape[1], # or EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x23aa646a0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer #3D tensor with shape: (batch_size, sequence_length, output_dim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 300)           817200    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 14, 300)           270300    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 453       \n",
      "=================================================================\n",
      "Total params: 1,133,103\n",
      "Trainable params: 315,903\n",
      "Non-trainable params: 817,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "\n",
    "## model1\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(300, 3, padding='valid',activation='relu',strides=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283846 samples, validate on 121647 samples\n",
      "Epoch 1/2\n",
      "283846/283846 [==============================] - 87s 308us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0016 - val_acc: 0.9998\n",
      "Epoch 2/2\n",
      "283846/283846 [==============================] - 93s 327us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0016 - val_acc: 0.9998\n",
      "Test loss: 0.001613334781730237\n",
      "Test accuracy: 0.9997698258074593\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2, batch_size=128)\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Predicted category:  clothing\n",
      "----------\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Clothing Probability:  1.0\n",
      "Camera Probability:  3.271633e-19\n",
      "home appliances probability:  3.826175e-11\n"
     ]
    }
   ],
   "source": [
    "example_product = \"Drawcord on elastic waist; mesh insert below back waist\"\n",
    "example_product = preprocess(example_product)\n",
    "example_sequence = tokenizer.texts_to_sequences([example_product])\n",
    "example_padded_sequence = pad_sequences(example_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"-\"*10)\n",
    "print(\"Predicted category: \", category_reverse_index[model.predict_classes(example_padded_sequence, verbose=0)[0]])\n",
    "print(\"-\"*10)\n",
    "probabilities = model.predict(example_padded_sequence, verbose=1)\n",
    "probabilities = probabilities[0]\n",
    "print(\"Clothing Probability: \",probabilities[category_index[\"clothing\"]] )\n",
    "print(\"Camera Probability: \",probabilities[category_index[\"camera\"]] )\n",
    "print(\"home appliances probability: \",probabilities[category_index[\"home-appliances\"]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
