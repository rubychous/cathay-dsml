{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "tw_credit = pd.read_csv('/Users/ruby/Desktop/tw_credit_card.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_credit.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'default.payment.next.month'\n",
    "predictors = ['AGE', 'SEX', 'LIMIT_BAL']\n",
    "cols = ['AGE', 'SEX', 'LIMIT_BAL','default.payment.next.month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_credit = tw_credit[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.485500</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>0.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.217904</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>0.415062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGE           SEX       LIMIT_BAL  default.payment.next.month\n",
       "count  30000.000000  30000.000000    30000.000000                30000.000000\n",
       "mean      35.485500      1.603733   167484.322667                    0.221200\n",
       "std        9.217904      0.489129   129747.661567                    0.415062\n",
       "min       21.000000      1.000000    10000.000000                    0.000000\n",
       "25%       28.000000      1.000000    50000.000000                    0.000000\n",
       "50%       34.000000      2.000000   140000.000000                    0.000000\n",
       "75%       41.000000      2.000000   240000.000000                    0.000000\n",
       "max       79.000000      2.000000  1000000.000000                    1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_credit.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12a2236a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(tw_credit.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input features and target variables\n",
    "X= tw_credit[predictors]\n",
    "y= tw_credit[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruby/Documents/Virtual_Env/dev/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X['LIMIT_BAL'] = np.log(X['LIMIT_BAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>9.903488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>11.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>11.407565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX  LIMIT_BAL\n",
       "0   24    2   9.903488\n",
       "1   26    2  11.695247\n",
       "2   34    2  11.407565"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Build NN Model\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, Activation, Flatten\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ruby/Documents/Virtual_Env/dev/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(3, activation='relu',\n",
    "                     input_dim=3, name = 'hidden_layer1'))\n",
    "\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(20, activation='relu', name = 'hidden_layer2'))\n",
    "\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(15, activation='relu', name = 'hidden_layer3'))\n",
    "\n",
    "#Fourth  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', name = 'hidden_layer4'))\n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', name = 'tw_output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer = 'Adam',\n",
    "                   loss='binary_crossentropy', \n",
    "                   metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ruby/Documents/Virtual_Env/dev/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "24000/24000 [==============================] - 1s 47us/step - loss: 0.5412 - acc: 0.7715: 1s - loss: 0.5708 -\n",
      "Epoch 2/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5308 - acc: 0.7776\n",
      "Epoch 3/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5271 - acc: 0.7776\n",
      "Epoch 4/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5254 - acc: 0.7776\n",
      "Epoch 5/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5247 - acc: 0.7776\n",
      "Epoch 6/100\n",
      "24000/24000 [==============================] - 1s 35us/step - loss: 0.5250 - acc: 0.7776\n",
      "Epoch 7/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5244 - acc: 0.7776\n",
      "Epoch 8/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5240 - acc: 0.7776\n",
      "Epoch 9/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5233 - acc: 0.7776\n",
      "Epoch 10/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5237 - acc: 0.7776\n",
      "Epoch 11/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5233 - acc: 0.7776\n",
      "Epoch 12/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5226 - acc: 0.7776\n",
      "Epoch 13/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5230 - acc: 0.7776\n",
      "Epoch 14/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5226 - acc: 0.7776\n",
      "Epoch 15/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5225 - acc: 0.7776\n",
      "Epoch 16/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5219 - acc: 0.7776\n",
      "Epoch 17/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5215 - acc: 0.7776\n",
      "Epoch 18/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5215 - acc: 0.7776\n",
      "Epoch 19/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5204 - acc: 0.7776\n",
      "Epoch 20/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5206 - acc: 0.7776\n",
      "Epoch 21/100\n",
      "24000/24000 [==============================] - 1s 34us/step - loss: 0.5199 - acc: 0.7776\n",
      "Epoch 22/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5201 - acc: 0.7776\n",
      "Epoch 23/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5202 - acc: 0.7776\n",
      "Epoch 24/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5196 - acc: 0.7776\n",
      "Epoch 25/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5192 - acc: 0.7776\n",
      "Epoch 26/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5187 - acc: 0.7776\n",
      "Epoch 27/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5186 - acc: 0.7776\n",
      "Epoch 28/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5185 - acc: 0.7776\n",
      "Epoch 29/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5182 - acc: 0.7776\n",
      "Epoch 30/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5177 - acc: 0.7776\n",
      "Epoch 31/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5185 - acc: 0.7776\n",
      "Epoch 32/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5175 - acc: 0.7776\n",
      "Epoch 33/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5175 - acc: 0.7776\n",
      "Epoch 34/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5171 - acc: 0.7776\n",
      "Epoch 35/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5167 - acc: 0.7776\n",
      "Epoch 36/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5173 - acc: 0.7776\n",
      "Epoch 37/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5169 - acc: 0.7776\n",
      "Epoch 38/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5165 - acc: 0.7776\n",
      "Epoch 39/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5162 - acc: 0.7776\n",
      "Epoch 40/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5168 - acc: 0.7776\n",
      "Epoch 41/100\n",
      "24000/24000 [==============================] - 1s 34us/step - loss: 0.5169 - acc: 0.7777\n",
      "Epoch 42/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5168 - acc: 0.7776\n",
      "Epoch 43/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5169 - acc: 0.7776\n",
      "Epoch 44/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5162 - acc: 0.7776\n",
      "Epoch 45/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5162 - acc: 0.7776\n",
      "Epoch 46/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5165 - acc: 0.7776\n",
      "Epoch 47/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5159 - acc: 0.7776\n",
      "Epoch 48/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5162 - acc: 0.7776\n",
      "Epoch 49/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 50/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5156 - acc: 0.7776\n",
      "Epoch 51/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 52/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5154 - acc: 0.7776\n",
      "Epoch 53/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5157 - acc: 0.7776\n",
      "Epoch 54/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 55/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5159 - acc: 0.7776\n",
      "Epoch 56/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 57/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5157 - acc: 0.7776\n",
      "Epoch 58/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5160 - acc: 0.7777\n",
      "Epoch 59/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5157 - acc: 0.7776\n",
      "Epoch 60/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5153 - acc: 0.7776\n",
      "Epoch 61/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5153 - acc: 0.7776\n",
      "Epoch 62/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5151 - acc: 0.7777\n",
      "Epoch 63/100\n",
      "24000/24000 [==============================] - 1s 35us/step - loss: 0.5156 - acc: 0.7776\n",
      "Epoch 64/100\n",
      "24000/24000 [==============================] - 1s 35us/step - loss: 0.5154 - acc: 0.7776\n",
      "Epoch 65/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5157 - acc: 0.7776\n",
      "Epoch 66/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5159 - acc: 0.7777\n",
      "Epoch 67/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 68/100\n",
      "24000/24000 [==============================] - 1s 33us/step - loss: 0.5154 - acc: 0.7776\n",
      "Epoch 69/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 70/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5153 - acc: 0.7776\n",
      "Epoch 71/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5153 - acc: 0.7776\n",
      "Epoch 72/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 73/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 74/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5157 - acc: 0.7776\n",
      "Epoch 75/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5154 - acc: 0.7777\n",
      "Epoch 76/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 77/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5150 - acc: 0.7775\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5153 - acc: 0.7776\n",
      "Epoch 79/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5151 - acc: 0.7776\n",
      "Epoch 80/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 81/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 82/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5151 - acc: 0.7776\n",
      "Epoch 83/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5154 - acc: 0.7775\n",
      "Epoch 84/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 85/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5158 - acc: 0.7777\n",
      "Epoch 86/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5150 - acc: 0.7776\n",
      "Epoch 87/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 88/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5150 - acc: 0.7776\n",
      "Epoch 89/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5154 - acc: 0.7775\n",
      "Epoch 90/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 91/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5149 - acc: 0.7776\n",
      "Epoch 92/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5149 - acc: 0.7776\n",
      "Epoch 93/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5153 - acc: 0.7776\n",
      "Epoch 94/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5157 - acc: 0.7776\n",
      "Epoch 95/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 96/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5148 - acc: 0.7776\n",
      "Epoch 97/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5155 - acc: 0.7776\n",
      "Epoch 98/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5146 - acc: 0.7776\n",
      "Epoch 99/100\n",
      "24000/24000 [==============================] - 1s 31us/step - loss: 0.5152 - acc: 0.7776\n",
      "Epoch 100/100\n",
      "24000/24000 [==============================] - 1s 32us/step - loss: 0.5158 - acc: 0.7776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13dc6add8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train, y_train, batch_size=30, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another Way\n",
    "# from keras.optimizers import SGD\n",
    "# opt = SGD(lr=0.01)\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 0s 11us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5153253032366435, 0.777625]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "classifier.save('neural_network_0602.h5')\n",
    "classifier.save_weights('neural_network_0602_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_model_pre_train = load_model('neural_network_0602.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer1 (Dense)        (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "tw_output_layer (Dense)      (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 544\n",
      "Trainable params: 544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.43687257,  0.5460751 ,  0.7315992 ],\n",
       "        [ 0.88109255, -0.02151354, -0.52715313],\n",
       "        [ 0.07291427,  1.682757  , -0.1738082 ]], dtype=float32),\n",
       " array([ 0.86661476, -1.3172103 ,  1.0770884 ], dtype=float32),\n",
       " array([[-0.38038912, -0.17480376,  0.4517123 , -0.37197337,  0.20609543,\n",
       "         -0.44433287, -0.44622323, -0.18620089, -0.45449093,  0.1151405 ,\n",
       "         -0.00120604, -0.36829033, -0.31854293,  0.5314405 , -0.26923758,\n",
       "          0.1290986 ,  0.08267498, -0.5014108 ,  0.29396638,  0.00868476],\n",
       "        [ 0.29864782, -0.44013667, -0.14006472, -0.06383595,  0.5354582 ,\n",
       "          0.00764101, -0.02984186, -0.32977372, -0.13274962, -0.08771458,\n",
       "         -0.34508792, -0.17344442, -0.08063957, -0.50894046,  0.04707258,\n",
       "         -0.2388801 , -0.16160682, -0.01680306,  0.04057833,  0.03868085],\n",
       "        [-0.42899606,  0.38837218, -0.4083954 , -0.01922837, -0.4232588 ,\n",
       "          0.27624893,  0.2937241 ,  0.0804953 , -0.35039198, -0.45622253,\n",
       "         -0.21149793, -0.05870664,  0.21039492,  0.4914678 ,  0.03853586,\n",
       "         -0.42998138,  0.07037532,  0.29418397, -0.46928102, -0.10858668]],\n",
       "       dtype=float32),\n",
       " array([-0.13693629,  0.        ,  0.01405936,  0.        , -1.1825299 ,\n",
       "        -0.54934794, -0.0069897 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.2585135 , -0.85737747,\n",
       "         0.        ,  0.        , -0.8510139 , -0.3150748 , -0.13599518],\n",
       "       dtype=float32),\n",
       " array([[ 7.69625381e-02,  1.03286833e-01,  1.80258706e-01,\n",
       "         -3.90531421e-02, -1.95630744e-01,  1.98800296e-01,\n",
       "          2.95778215e-01, -9.73504782e-03,  1.49561139e-02,\n",
       "          2.80028760e-01, -5.41201606e-02,  3.44370097e-01,\n",
       "          1.01239115e-01,  2.69257128e-02,  1.28343612e-01],\n",
       "        [-2.55309522e-01,  1.97074085e-01,  1.31090432e-01,\n",
       "         -1.87219679e-01, -3.60986918e-01,  1.34921342e-01,\n",
       "         -3.18144441e-01, -1.73234940e-03,  2.78999537e-01,\n",
       "          2.61153489e-01,  1.49700046e-03, -7.86449909e-02,\n",
       "         -2.86654294e-01, -1.13544464e-01, -1.37110054e-01],\n",
       "        [-2.16666564e-01, -6.40981793e-02,  1.76749364e-01,\n",
       "         -1.04684643e-02, -2.01447845e-01,  1.18493825e-01,\n",
       "         -1.65157259e-01, -8.85756016e-02,  1.19701922e-01,\n",
       "         -8.30980241e-02,  2.24072382e-01,  2.03186065e-01,\n",
       "          6.96845055e-02,  1.16256386e-01,  2.20649332e-01],\n",
       "        [ 1.97289556e-01,  2.45102495e-01,  9.78916585e-02,\n",
       "          3.39775234e-01,  1.67851359e-01,  2.18219846e-01,\n",
       "         -3.67648005e-02,  1.13090187e-01, -1.69849351e-01,\n",
       "         -1.41076982e-01, -1.47988409e-01,  9.68308747e-02,\n",
       "         -2.18230397e-01,  5.68645000e-02, -1.99974209e-01],\n",
       "        [-1.03309795e-01, -4.37267363e-01,  2.60902077e-01,\n",
       "          5.42993069e-01,  2.53535271e-01, -7.67838061e-02,\n",
       "          1.96015120e-01, -1.74929887e-01, -1.23552442e-01,\n",
       "         -2.45265253e-02,  1.26153022e-01, -1.48103125e-02,\n",
       "         -4.19824719e-02, -2.60703564e-01, -2.01704189e-01],\n",
       "        [-1.85146570e-01, -2.42093936e-01, -4.86814976e-02,\n",
       "         -2.03996584e-01,  2.51492947e-01, -2.79734939e-01,\n",
       "         -2.99654514e-01, -3.18019986e-01, -4.07540262e-01,\n",
       "         -5.49983025e-01, -9.56416782e-03,  2.74278462e-01,\n",
       "         -7.93122798e-02,  6.67438507e-02,  3.80648673e-02],\n",
       "        [-7.24928081e-02, -3.38757366e-01,  2.53583580e-01,\n",
       "         -9.65151638e-02,  2.61342049e-01,  1.19923145e-01,\n",
       "          2.50889748e-01, -1.86830744e-01,  3.39732558e-01,\n",
       "          4.04952973e-01,  2.51424581e-01, -8.10843706e-03,\n",
       "          3.45708460e-01, -1.36573434e-01,  1.01253420e-01],\n",
       "        [ 1.96446031e-01,  3.87602061e-01, -3.88652891e-01,\n",
       "         -9.46888924e-02,  1.26856238e-01, -2.09977657e-01,\n",
       "          3.42772394e-01,  3.10930610e-03, -3.04269195e-02,\n",
       "         -1.39912158e-01,  1.22619539e-01, -3.60135794e-01,\n",
       "          6.74401820e-02,  4.03395623e-01, -3.19723010e-01],\n",
       "        [-1.03170961e-01,  2.20120281e-01,  7.40696788e-02,\n",
       "         -2.73647547e-01,  7.26252794e-02,  3.94728214e-01,\n",
       "         -3.18631530e-01, -1.52934402e-01, -2.78824717e-01,\n",
       "         -3.40040147e-01,  1.89574659e-02, -1.80721983e-01,\n",
       "          1.43149287e-01, -9.69715714e-02, -5.57896495e-03],\n",
       "        [-2.52413452e-02,  3.80438566e-02, -1.14997953e-01,\n",
       "          3.64670545e-01, -2.58088410e-01,  4.11831766e-01,\n",
       "         -3.77805829e-02,  3.46397191e-01, -3.59938383e-01,\n",
       "         -3.89434516e-01, -4.78750467e-02, -1.05638027e-01,\n",
       "          4.04709905e-01,  1.21949643e-01,  1.58464283e-01],\n",
       "        [-1.94548965e-02, -2.20906064e-01,  3.46103221e-01,\n",
       "         -3.43514234e-01,  2.46988446e-01, -1.59810275e-01,\n",
       "          2.07772762e-01, -1.89728022e-01,  2.19761759e-01,\n",
       "         -1.01332188e-01, -5.92746139e-02,  3.73788446e-01,\n",
       "         -1.93601578e-01, -1.86019212e-01, -2.45068654e-01],\n",
       "        [ 1.29991204e-01, -1.46748543e-01, -2.45486513e-01,\n",
       "         -4.87234890e-02, -3.09635341e-01, -2.37435445e-01,\n",
       "          2.63008088e-01,  3.52392048e-01, -3.22033614e-01,\n",
       "          2.78365999e-01, -4.01103973e-01,  2.23440558e-01,\n",
       "         -2.65852213e-01,  3.16074491e-03,  2.80857086e-04],\n",
       "        [ 1.59847736e-02,  3.39701563e-01, -6.81756139e-02,\n",
       "          1.67814165e-01, -1.69273853e-01, -1.57055348e-01,\n",
       "         -2.46984705e-01,  1.27403051e-01,  3.67622405e-01,\n",
       "         -4.00964290e-01, -2.57264644e-01, -8.73312950e-02,\n",
       "         -1.48388594e-01, -1.37464613e-01, -3.31321955e-02],\n",
       "        [-3.82222056e-01,  3.15388560e-01,  6.32232148e-03,\n",
       "         -7.25057945e-02, -2.35202268e-01,  5.23124710e-02,\n",
       "         -9.07577127e-02,  3.95706557e-02,  1.91313792e-02,\n",
       "         -4.37665939e-01, -2.73049980e-01, -6.60515875e-02,\n",
       "         -1.01250701e-01,  1.68311566e-01,  8.46734643e-03],\n",
       "        [ 1.81474656e-01, -3.12584072e-01,  2.87990451e-01,\n",
       "          2.52197683e-01, -4.17339131e-02, -4.55465131e-02,\n",
       "         -5.21389246e-01, -1.59326762e-01,  3.44368339e-01,\n",
       "         -5.97122252e-01,  1.37402713e-01, -1.98603630e-01,\n",
       "         -1.05984528e-02, -3.24449360e-01, -2.85900176e-01],\n",
       "        [ 3.58280927e-01, -2.31200457e-03, -1.83521435e-01,\n",
       "         -4.17098403e-03, -3.87230814e-01,  1.82159245e-02,\n",
       "          3.51902515e-01,  1.73178107e-01, -2.12205946e-01,\n",
       "          7.33914971e-03, -3.67879093e-01,  3.60420376e-01,\n",
       "          3.54586750e-01, -2.27861494e-01, -3.20193470e-01],\n",
       "        [-1.61304116e-01, -1.66093454e-01,  2.51875520e-02,\n",
       "          3.41102153e-01,  3.90016735e-02, -1.17626816e-01,\n",
       "         -2.92891949e-01, -3.14370990e-01, -3.34981143e-01,\n",
       "          1.28526390e-02, -3.74816656e-01,  2.70588249e-01,\n",
       "         -3.92321020e-01,  1.45207345e-02, -1.62253946e-01],\n",
       "        [-2.51858216e-02,  3.41788769e-01,  1.31389230e-01,\n",
       "         -4.31891605e-02, -9.59619805e-02, -4.07370865e-01,\n",
       "          5.19324988e-02,  1.30412087e-01, -2.21288487e-01,\n",
       "         -3.17097127e-01, -1.27370972e-02, -1.38473175e-02,\n",
       "         -9.71694365e-02, -3.61621648e-01,  3.21149319e-01],\n",
       "        [-5.06997807e-03,  2.63059378e-01, -2.69664168e-01,\n",
       "         -2.13930219e-01,  2.13769749e-01, -2.09040657e-01,\n",
       "          3.16694230e-01, -2.85850465e-01, -1.36287123e-01,\n",
       "         -4.07772392e-01, -4.02639478e-01, -2.89390296e-01,\n",
       "         -1.66859537e-01, -8.72866809e-02, -2.34523952e-01],\n",
       "        [-1.27688020e-01, -1.25213534e-01, -2.08426580e-01,\n",
       "         -3.55097167e-02,  3.51648241e-01, -1.87810287e-01,\n",
       "         -3.93830180e-01,  1.78304881e-01,  2.12403238e-01,\n",
       "         -1.71782732e-01,  1.97024673e-01,  2.78084010e-01,\n",
       "         -1.41943410e-01,  9.12558138e-02, -3.95858377e-01]], dtype=float32),\n",
       " array([-0.05957477, -0.03146396, -1.0254469 , -1.0569549 , -1.0896009 ,\n",
       "        -0.03153285, -0.68227   , -0.04815755,  1.0295185 , -0.16432244,\n",
       "        -1.0622295 , -0.05992468, -0.14896625,  0.        ,  0.        ],\n",
       "       dtype=float32),\n",
       " array([[ 0.07698733, -0.12061369,  0.12288088, -0.05166485, -0.0169531 ,\n",
       "          0.42838323, -0.37359795,  0.4309408 ],\n",
       "        [-0.09413692, -0.34118932,  0.41649026,  0.01560891,  0.28974867,\n",
       "          0.03646255, -0.1375727 , -0.5032215 ],\n",
       "        [-0.29100963, -0.35267523, -0.19374314, -0.15358122,  0.5118456 ,\n",
       "          0.06663865, -0.41163352, -0.37540847],\n",
       "        [-0.16930279, -0.06851473, -0.2574856 ,  0.5632537 ,  0.36390173,\n",
       "         -0.38074523, -0.27792957, -0.34132838],\n",
       "        [-0.18118942,  0.48847818, -0.31240714,  0.7083144 ,  0.19467887,\n",
       "          0.47634876,  0.50855833,  0.44481152],\n",
       "        [ 0.35461205, -0.05508667,  0.32927406,  0.31171936, -0.11194716,\n",
       "          0.39148057, -0.48183972,  0.26927042],\n",
       "        [-0.15289956, -0.21675548,  0.37288827,  0.1785469 ,  0.09309579,\n",
       "          0.11498547, -0.4687429 ,  0.4704795 ],\n",
       "        [ 0.23814046, -0.05992082,  0.387725  , -0.45968464, -0.01685201,\n",
       "          0.3268699 , -0.06555223,  0.11246085],\n",
       "        [ 0.0010795 , -0.38250226, -0.10945076, -0.11480875,  0.03720336,\n",
       "          0.17881662,  0.29914454, -0.3190378 ],\n",
       "        [ 0.17839605,  0.34603947, -0.08975065,  0.00967495, -0.02267872,\n",
       "         -0.13381368, -0.20161602,  0.10044235],\n",
       "        [-0.21324733, -0.484348  ,  0.3437652 ,  0.6211225 ,  0.18866487,\n",
       "          0.22339392, -0.14110938, -0.3341874 ],\n",
       "        [-0.18184066,  0.00182414,  0.12031168,  0.5278678 , -0.41072986,\n",
       "          0.3452071 ,  0.29073277,  0.328017  ],\n",
       "        [ 0.34376895, -0.13240355,  0.11869699, -0.30235812,  0.18972638,\n",
       "          0.16806747, -0.07611512, -0.40545636],\n",
       "        [ 0.16105384,  0.19251847, -0.04769883, -0.1252574 ,  0.35766196,\n",
       "         -0.031795  , -0.02150857, -0.46276397],\n",
       "        [ 0.12930638,  0.38959175,  0.2561165 ,  0.33375204, -0.24082896,\n",
       "         -0.4127109 , -0.08441174, -0.19363296]], dtype=float32),\n",
       " array([ 0.        ,  0.        ,  0.        , -0.89014786, -0.8797807 ,\n",
       "        -0.02237275,  0.00600219,  0.        ], dtype=float32),\n",
       " array([[-0.7498945 ],\n",
       "        [ 0.03922635],\n",
       "        [ 0.23196125],\n",
       "        [-0.30164775],\n",
       "        [-0.37481496],\n",
       "        [ 0.6345624 ],\n",
       "        [-0.30407676],\n",
       "        [-0.77760935]], dtype=float32),\n",
       " array([0.7557075], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_model_pre_train.summary()\n",
    "tw_model_pre_train.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 - German Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_credit = pd.read_pickle('german_sample.pk')\n",
    "german_credit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping dictionary\n",
    "dict_gender = {'male': 1, 'female': 2}\n",
    "dict_risk = {'good': 0, 'bad': 1}\n",
    "dict_purpose = {'radio/TV':0, 'education':1, 'furniture/equipment':2, 'car':3, \n",
    "                'business':4,'domestic appliances':5, 'repairs':6, 'vacation/others':7}\n",
    "dict_housing = {'own':1, 'free':2, 'rent':3}\n",
    "dict_saving_acct = {'little':1, 'quite rich':2, 'rich':3, 'moderate':4}\n",
    "dict_checking_acct = {'little':1, 'moderate':2,'rich':3}\n",
    "\n",
    "\n",
    "german_credit.replace({\"Sex\": dict_gender}, inplace = True)\n",
    "german_credit.replace({\"Risk\": dict_risk}, inplace = True)\n",
    "german_credit.replace({\"Purpose\": dict_purpose}, inplace = True)\n",
    "german_credit.replace({\"Housing\": dict_housing}, inplace = True)\n",
    "german_credit.replace({\"Saving accounts\": dict_saving_acct}, inplace = True)\n",
    "german_credit.replace({\"Checking account\": dict_checking_acct}, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# rename columns\n",
    "german_credit_new = german_credit.rename(columns = {'Sex':'SEX',\n",
    "                                                    'Age':'AGE',\n",
    "                                                    'Credit amount':'LIMIT_BAL',\n",
    "                                                    'Risk':'default.payment.next.month'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'default.payment.next.month'\n",
    "# predictors = ['AGE', 'SEX', 'Job', 'Housing', 'Saving accounts', 'Checking account',\n",
    "#        'LIMIT_BAL', 'Duration', 'Purpose']\n",
    "\n",
    "predictors = ['AGE', 'SEX', 'LIMIT_BAL']\n",
    "\n",
    "german_x = german_credit_new[predictors]\n",
    "german_y = german_credit_new[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 3), (200,), (50, 3), (50,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test split\n",
    "x_train_german, x_test_german, y_train_german, y_test_german = train_test_split(\n",
    "    german_x, german_y, test_size=0.2)\n",
    "\n",
    "x_train_german.shape, y_train_german.shape, x_test_german.shape, y_test_german.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-train Model\n",
    "base_model = load_model('neural_network_0602.h5')\n",
    "tw_model_output = base_model.output\n",
    "\n",
    "\n",
    "# Initialize model for Fine Tune Model\n",
    "german_model = Sequential()\n",
    "german_model.load_weights('neural_network_0602_weights.h5', by_name = True)\n",
    "\n",
    "\n",
    "for layer in base_model.layers[:-2]: # remove the last 2 layers in pre-train model\n",
    "    german_model.add(layer)    \n",
    "\n",
    "# Freeze the layers [pre-train model]\n",
    "for layer in german_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "#german_model.add(Flatten(name='hidden_layer3'))(tw_model_output)\n",
    "\n",
    "    \n",
    "# German Fine Tune Model\n",
    "#First Hidden Layer\n",
    "german_model.add(Dense(30, activation='relu',\n",
    "                     input_dim=9))\n",
    "\n",
    "#Second  Hidden Layer\n",
    "german_model.add(Dense(15, activation='relu'))\n",
    "\n",
    "#Third  Hidden Layer\n",
    "german_model.add(Dense(8, activation='relu'))\n",
    "\n",
    "#Fourth  Hidden Layer\n",
    "german_model.add(Dense(4, activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "german_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "german_model.compile(optimizer = 'Adam',\n",
    "                   loss='binary_crossentropy', \n",
    "                   metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer1 (Dense)        (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,521\n",
      "Trainable params: 1,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "german_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7127 - acc: 0.4000 - val_loss: 0.6874 - val_acc: 0.6200\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6803 - acc: 0.6550 - val_loss: 0.6737 - val_acc: 0.6400\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.6660 - acc: 0.6550 - val_loss: 0.6656 - val_acc: 0.6400\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6561 - acc: 0.6550 - val_loss: 0.6582 - val_acc: 0.6400\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 124us/step - loss: 0.6474 - acc: 0.6550 - val_loss: 0.6543 - val_acc: 0.6400\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.6447 - acc: 0.6550 - val_loss: 0.6545 - val_acc: 0.6400\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 128us/step - loss: 0.6446 - acc: 0.6550 - val_loss: 0.6533 - val_acc: 0.6400\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.6490 - acc: 0.6550 - val_loss: 0.6488 - val_acc: 0.6400\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 130us/step - loss: 0.6430 - acc: 0.6550 - val_loss: 0.6503 - val_acc: 0.6400\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.6423 - acc: 0.6550 - val_loss: 0.6487 - val_acc: 0.6400\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.6417 - acc: 0.6550 - val_loss: 0.6462 - val_acc: 0.6400\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.6421 - acc: 0.6550 - val_loss: 0.6440 - val_acc: 0.6400\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.6466 - acc: 0.6550 - val_loss: 0.6499 - val_acc: 0.6400\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.6397 - acc: 0.6550 - val_loss: 0.6408 - val_acc: 0.6400\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 123us/step - loss: 0.6450 - acc: 0.6550 - val_loss: 0.6394 - val_acc: 0.6400\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.6444 - acc: 0.6550 - val_loss: 0.6474 - val_acc: 0.6400\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.6467 - acc: 0.6550 - val_loss: 0.6498 - val_acc: 0.6400\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.6436 - acc: 0.6550 - val_loss: 0.6471 - val_acc: 0.6400\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.6406 - acc: 0.6550 - val_loss: 0.6463 - val_acc: 0.6400\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6414 - acc: 0.6550 - val_loss: 0.6479 - val_acc: 0.6400\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6407 - acc: 0.6550 - val_loss: 0.6448 - val_acc: 0.6400\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6425 - acc: 0.6550 - val_loss: 0.6424 - val_acc: 0.6400\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.6433 - acc: 0.6550 - val_loss: 0.6421 - val_acc: 0.6400\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.6401 - acc: 0.6550 - val_loss: 0.6449 - val_acc: 0.6400\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6413 - acc: 0.6550 - val_loss: 0.6418 - val_acc: 0.6400\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.6414 - acc: 0.6550 - val_loss: 0.6447 - val_acc: 0.6400\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.6385 - acc: 0.6550 - val_loss: 0.6430 - val_acc: 0.6400\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.6422 - acc: 0.6550 - val_loss: 0.6416 - val_acc: 0.6400\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.6433 - acc: 0.6550 - val_loss: 0.6459 - val_acc: 0.6400\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.6381 - acc: 0.6550 - val_loss: 0.6435 - val_acc: 0.6400\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.6391 - acc: 0.6550 - val_loss: 0.6429 - val_acc: 0.6400\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.6390 - acc: 0.6550 - val_loss: 0.6441 - val_acc: 0.6400\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.6394 - acc: 0.6550 - val_loss: 0.6392 - val_acc: 0.6400\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.6383 - acc: 0.6550 - val_loss: 0.6403 - val_acc: 0.6400\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.6378 - acc: 0.6550 - val_loss: 0.6434 - val_acc: 0.6400\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6383 - acc: 0.6550 - val_loss: 0.6429 - val_acc: 0.6400\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.6384 - acc: 0.6550 - val_loss: 0.6416 - val_acc: 0.6400\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.6381 - acc: 0.6550 - val_loss: 0.6428 - val_acc: 0.6400\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6381 - acc: 0.6550 - val_loss: 0.6413 - val_acc: 0.6400\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.6376 - acc: 0.6550 - val_loss: 0.6419 - val_acc: 0.6400\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 115us/step - loss: 0.6382 - acc: 0.6550 - val_loss: 0.6417 - val_acc: 0.6400\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.6370 - acc: 0.6550 - val_loss: 0.6417 - val_acc: 0.6400\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.6408 - acc: 0.6550 - val_loss: 0.6432 - val_acc: 0.6400\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6394 - acc: 0.6550 - val_loss: 0.6404 - val_acc: 0.6400\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 102us/step - loss: 0.6384 - acc: 0.6550 - val_loss: 0.6414 - val_acc: 0.6400\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 94us/step - loss: 0.6383 - acc: 0.6550 - val_loss: 0.6419 - val_acc: 0.6400\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6387 - acc: 0.6550 - val_loss: 0.6425 - val_acc: 0.6400\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.6389 - acc: 0.6550 - val_loss: 0.6391 - val_acc: 0.6400\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 97us/step - loss: 0.6373 - acc: 0.6550 - val_loss: 0.6414 - val_acc: 0.6400\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.6374 - acc: 0.6550 - val_loss: 0.6407 - val_acc: 0.6400\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6389 - acc: 0.6600 - val_loss: 0.6406 - val_acc: 0.6400\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 98us/step - loss: 0.6372 - acc: 0.6550 - val_loss: 0.6429 - val_acc: 0.6400\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6361 - acc: 0.6550 - val_loss: 0.6384 - val_acc: 0.6400\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6393 - acc: 0.6550 - val_loss: 0.6388 - val_acc: 0.6400\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.6372 - acc: 0.6550 - val_loss: 0.6403 - val_acc: 0.6400\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.6379 - acc: 0.6550 - val_loss: 0.6402 - val_acc: 0.6400\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6362 - acc: 0.6550 - val_loss: 0.6401 - val_acc: 0.6400\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 112us/step - loss: 0.6372 - acc: 0.6500 - val_loss: 0.6386 - val_acc: 0.6400\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 102us/step - loss: 0.6364 - acc: 0.6550 - val_loss: 0.6404 - val_acc: 0.6400\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.6385 - acc: 0.6550 - val_loss: 0.6408 - val_acc: 0.6400\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 104us/step - loss: 0.6370 - acc: 0.6550 - val_loss: 0.6391 - val_acc: 0.6400\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 100us/step - loss: 0.6424 - acc: 0.6550 - val_loss: 0.6367 - val_acc: 0.6400\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.6429 - acc: 0.6550 - val_loss: 0.6427 - val_acc: 0.6400\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.6374 - acc: 0.6550 - val_loss: 0.6412 - val_acc: 0.6400\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.6394 - acc: 0.6550 - val_loss: 0.6429 - val_acc: 0.6400\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.6376 - acc: 0.6550 - val_loss: 0.6416 - val_acc: 0.6400\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 101us/step - loss: 0.6385 - acc: 0.6550 - val_loss: 0.6429 - val_acc: 0.6400\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6363 - acc: 0.6550 - val_loss: 0.6409 - val_acc: 0.6400\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.6393 - acc: 0.6550 - val_loss: 0.6418 - val_acc: 0.6400\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.6376 - acc: 0.6550 - val_loss: 0.6419 - val_acc: 0.6400\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.6360 - acc: 0.6550 - val_loss: 0.6407 - val_acc: 0.6400\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 102us/step - loss: 0.6429 - acc: 0.6550 - val_loss: 0.6406 - val_acc: 0.6400\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.6394 - acc: 0.6550 - val_loss: 0.6415 - val_acc: 0.6400\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 98us/step - loss: 0.6366 - acc: 0.6550 - val_loss: 0.6397 - val_acc: 0.6400\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 100us/step - loss: 0.6376 - acc: 0.6600 - val_loss: 0.6393 - val_acc: 0.6400\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.6379 - acc: 0.6550 - val_loss: 0.6405 - val_acc: 0.6400\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.6363 - acc: 0.6550 - val_loss: 0.6396 - val_acc: 0.6400\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6361 - acc: 0.6550 - val_loss: 0.6388 - val_acc: 0.6400\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.6383 - acc: 0.6550 - val_loss: 0.6396 - val_acc: 0.6400\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.6345 - acc: 0.6600 - val_loss: 0.6384 - val_acc: 0.6400\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6364 - acc: 0.6600 - val_loss: 0.6380 - val_acc: 0.6400\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.6359 - acc: 0.6600 - val_loss: 0.6389 - val_acc: 0.6400\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6356 - acc: 0.6550 - val_loss: 0.6391 - val_acc: 0.6400\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.6349 - acc: 0.6600 - val_loss: 0.6369 - val_acc: 0.6400\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 103us/step - loss: 0.6387 - acc: 0.6550 - val_loss: 0.6359 - val_acc: 0.6400\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 102us/step - loss: 0.6416 - acc: 0.6550 - val_loss: 0.6394 - val_acc: 0.6400\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 106us/step - loss: 0.6400 - acc: 0.6550 - val_loss: 0.6383 - val_acc: 0.6400\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6395 - acc: 0.6550 - val_loss: 0.6413 - val_acc: 0.6400\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.6397 - acc: 0.6500 - val_loss: 0.6405 - val_acc: 0.6400\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.6352 - acc: 0.6550 - val_loss: 0.6392 - val_acc: 0.6400\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.6382 - acc: 0.6550 - val_loss: 0.6397 - val_acc: 0.6400\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 129us/step - loss: 0.6379 - acc: 0.6550 - val_loss: 0.6399 - val_acc: 0.6400\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.6360 - acc: 0.6550 - val_loss: 0.6396 - val_acc: 0.6400\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.6378 - acc: 0.6550 - val_loss: 0.6393 - val_acc: 0.6400\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 127us/step - loss: 0.6366 - acc: 0.6550 - val_loss: 0.6395 - val_acc: 0.6400\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 122us/step - loss: 0.6352 - acc: 0.6550 - val_loss: 0.6393 - val_acc: 0.6400\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 119us/step - loss: 0.6351 - acc: 0.6600 - val_loss: 0.6338 - val_acc: 0.6400\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 117us/step - loss: 0.6361 - acc: 0.6600 - val_loss: 0.6367 - val_acc: 0.6400\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.6353 - acc: 0.6550 - val_loss: 0.6383 - val_acc: 0.6400\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.6345 - acc: 0.6600 - val_loss: 0.6357 - val_acc: 0.6400\n"
     ]
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "#german_model.fit(x_train_german, y_train_german, batch_size=30, epochs=100)\n",
    "\n",
    "# Another way\n",
    "model_output = german_model.fit(x_train_german, y_train_german,\n",
    "                         epochs=100,batch_size=15,\n",
    "                         verbose=1,validation_data=(x_test_german, y_test_german),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.634302921295166, 0.66]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=german_model.evaluate(x_train_german, y_train_german)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 58us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6356507015228271, 0.6399999976158142]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### predict \n",
    "german_nn_val_result = german_model.evaluate(x_test_german, y_test_german)\n",
    "german_nn_val_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
